{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt  \n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from random import random\n",
    "import json, os.path, pickle\n",
    "import sys, time\n",
    "from pathlib import Path\n",
    "print(f\"running python {sys.version}\")\n",
    "\n",
    "# condtional printing untility, only prints important messages\n",
    "global verbosity\n",
    "verbosity = 5\n",
    "def pp(importance, message):\n",
    "    if importance > 10-verbosity:\n",
    "        print(message)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Testing the learning curve mathematics based on three parameters.\")\n",
    "\n",
    "def success_p(attempt, baseline_success, final_success, half_time):\n",
    "    failure_risk = 0.5**(attempt/half_time) # in range 0 to 1\n",
    "    return final_success - failure_risk *(final_success - baseline_success)\n",
    "\n",
    "def plot_example_learning_curves():\n",
    "    bs = [55, 65] # percent\n",
    "    fs =[70,80] # percent\n",
    "    ht = [10, 20]\n",
    "    fig, ax = plt.subplots()\n",
    "    for baseline_success in bs:\n",
    "        for final_success in fs: # percent\n",
    "            for half_time in ht: # cases\n",
    "                x = np.array(range(0, 100))  \n",
    "                y = success_p(attempt = x, baseline_success = baseline_success, final_success = final_success, half_time = half_time)\n",
    "                plt.plot(x, y)  \n",
    "    plt.title(f\"Plot of {len(bs)*len(fs)*len(ht)} example learing curve assuming:\\n baseline_success={bs}%, final_success={fs}%, half_time={ht} attempts\")\n",
    "    ax.set_ylabel('Probability of success (%)')\n",
    "    ax.set_xlabel('Attempt number')\n",
    "    plt.show()  \n",
    "\n",
    "plot_example_learning_curves()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## Create a population of learning curves\n",
    "## (as three seperate arrays of the defining parameters)\n",
    "## \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Make mock curves as defined by three lists of defining parameters:\n",
    "* baseline success probablity (ie how well the student will do on first ever attempt)\n",
    "* final sussess probability (ie how well this stuedent will eventually become)\n",
    "* number of attempts to achieve half the improvement from baseline to final proficency\n",
    "\"\"\"\n",
    "def generate_student_curves(baseline_alpha, baseline_beta, fall_in_failure_rate, half_time_mean, n = 2000):\n",
    "    #baseline_success_p = 1/(1+np.random.exponential(odds_of_failure,n))\n",
    "    # see https://towardsdatascience.com/beta-distribution-intuition-examples-and-derivation-cf00f4db57af\n",
    "    baseline_success_p = np.random.beta(baseline_alpha, baseline_beta,n)\n",
    "    failure_p = 1-baseline_success_p # baseline risk of failure \n",
    "    final_success_p = 1-(failure_p * (1-fall_in_failure_rate*np.random.random(n)))\n",
    "    attempts_to_half_improvement = np.random.rayleigh(half_time_mean,n)\n",
    "    return {\"bsp\": baseline_success_p, \"fsp\": final_success_p, \"athi\": attempts_to_half_improvement}\n",
    "\n",
    "\"\"\" \n",
    "Describe a set of student curves, and optionally plot.\n",
    "Return a dictionary of values.                      \n",
    "\"\"\"\n",
    "def describe_student_curves(sc, meta, chattiness=1):\n",
    "    pp(chattiness, f\"\"\"      \n",
    "    baseline_success_p = {sc['bsp'].mean():0.2f} (sd: {sc['bsp'].std():0.2f})\n",
    "    final_success_p = {sc['fsp'].mean():0.2f} (sd: {sc['fsp'].std():0.2f})\n",
    "    attempts_to_half_improvement = {sc['athi'].mean():0.2f} (sd: {sc['athi'].std():0.2f})\n",
    "    \"\"\")    \n",
    "    return {\n",
    "      **meta,\n",
    "      \"baseline_success_p\": sc['bsp'].mean(),\n",
    "      \"baseline_success_p_sd\": sc['bsp'].std(),     \n",
    "      \"final_success_p\": sc['fsp'].mean(), \n",
    "      \"final_success_p_sd\": sc['fsp'].std(),\n",
    "      \"attempts_to_half_improvement\": sc['athi'].mean(),\n",
    "      \"attempts_to_half_improvement_sd\": sc['athi'].std(),\n",
    "      \"key\": f\"{sc['bsp'].mean():0.2f}_{sc['bsp'].std():0.2f}_{sc['fsp'].mean():0.2f}_{sc['fsp'].std():0.2f}_{sc['athi'].mean():0.2f}_{sc['athi'].std():0.2f}\"\n",
    "        }\n",
    "\n",
    "def plot_student_curve(sc):\n",
    "    n = len(sc['bsp'])\n",
    "    fig, (ax0, ax1) = plt.subplots(ncols=2, figsize=(8, 2))\n",
    "    count, bins, ignored = ax0.hist(sc['bsp'], bins=100, density=True, alpha=0.6, label=\"Baseline\")\n",
    "    count, bins, ignored = ax0.hist(sc['fsp'], bins=100, density=True, alpha=0.6, range=(0,1), label=\"Final\")\n",
    "    ax0.axis((0,1,0,n/200))\n",
    "    ax0.set_title(\"Distribution of student's success probability\")\n",
    "    ax0.set_xlabel('Probability of success')\n",
    "    ax0.legend()\n",
    "    ax0.set(yticklabels=[]) \n",
    "    count, bins, ignored = ax1.hist(sc['athi'], bins=100, density=False)\n",
    "    ax1.set_title(\"Distribution of student's attempts\\nto make half ultimate improvement\")\n",
    "    ax1.set_xlabel('Attempt number')\n",
    "    ax1.set(yticklabels=[]) \n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\"\"\" \n",
    "Implement the student curve by calculating the probability of success at a given attempt. \n",
    "\"\"\" \n",
    "def student_p(student_id, attempt, sc):\n",
    "    failure_risk = 0.5**(attempt/sc['athi'][student_id]) # in range 0 to 1\n",
    "    return sc['fsp'][student_id] - failure_risk *(sc['fsp'][student_id] - sc['bsp'][student_id])\n",
    "        \n",
    "\"\"\"\n",
    "create a 2d array of student success probabilities\n",
    "\"\"\"\n",
    "def student_attempt_success(sc, attempts=20):\n",
    "    n = len(sc['bsp'])\n",
    "    students = np.array(range(0, n))\n",
    "    attempts = np.array(range(0, attempts))\n",
    "    # make a matrix from the above two arrays\n",
    "    return student_p(students[:,np.newaxis],attempts[np.newaxis,:],sc)    \n",
    "\n",
    "def succeeded(p, success_relative_increase):\n",
    "    random_roll = np.random.random(p.shape)\n",
    "    modified_success = 1 - ((1-p)/(1+success_relative_increase))\n",
    "    pp(7, f\"P initial: {p.mean():0.3}  P after adjustment: {modified_success.mean():0.3}; dice: {random_roll.mean():0.3}\")\n",
    "    return random_roll < modified_success\n",
    "\n",
    "def create_mock_students(baseline_alpha, baseline_beta, fall_in_failure_rate, half_time_mean, n = 2000, chattiness = 5):\n",
    "    # baseline \"beta\" curve defining initial success rate\n",
    "    sc = generate_student_curves(baseline_alpha, baseline_beta, fall_in_failure_rate, half_time_mean, n)\n",
    "    sac = student_attempt_success(sc, attempts=20)\n",
    "    pp(chattiness, f\"Generated attempt success curves for {n} students.\")\n",
    "    return sc, sac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create and cache a set of student curves\n",
    "\"\"\"\n",
    "def make_student_sets(n=100, chattiness=1):\n",
    "    metas = {\n",
    "        \"variable\": {\n",
    "            \"baseline_alpha\": 2,\n",
    "            \"baseline_beta\": 2,\n",
    "            \"fall_in_failure_rate\": 0.5, # how much do they improve (or does their failure rate drop)\n",
    "            \"half_time_mean\": 5, # how quickly to students learn?\n",
    "        },\n",
    "        \"uniform\": {\n",
    "            \"baseline_alpha\": 100,\n",
    "            \"baseline_beta\": 100,\n",
    "            \"fall_in_failure_rate\": 0, # how much do they improve (or does their failure rate drop)\n",
    "            \"half_time_mean\": 1000, # how quickly to students learn?\n",
    "        },\n",
    "        \"initial\": {\n",
    "            \"baseline_alpha\": 6,\n",
    "            \"baseline_beta\": 8,\n",
    "            \"fall_in_failure_rate\": .7, # how much do they improve (or does their failure rate drop)\n",
    "            \"half_time_mean\": 10, # how quickly to students learn?\n",
    "        },\n",
    "        \"second\": {\n",
    "            \"baseline_alpha\": 7,\n",
    "            \"baseline_beta\": 3,\n",
    "            \"fall_in_failure_rate\": .75, # how much do they improve (or does their failure rate drop)\n",
    "            \"half_time_mean\": 10, # how quickly to students learn?\n",
    "        }\n",
    "    }\n",
    "    student_sets = {}\n",
    "    for name, meta in metas.items():\n",
    "        print(f\"Making {name} {n}\")\n",
    "        sc, sac = create_mock_students(\n",
    "            baseline_alpha = meta['baseline_alpha'], \n",
    "            baseline_beta = meta['baseline_beta'],\n",
    "            fall_in_failure_rate = meta['fall_in_failure_rate'], # how much do they improve (or does their failure rate drop)\n",
    "            half_time_mean = meta['half_time_mean'], # how quickly to students learn?\n",
    "            chattiness=chattiness, n = n)   \n",
    "        final_meta = describe_student_curves(sc, meta)\n",
    "        student_sets[name] = {**final_meta, \"sc\":sc,\"sac\":sac}\n",
    "    return student_sets\n",
    "\n",
    "\n",
    "def load_student_sets(testing=True, student_sets_file_prefix=False, overwrite=False):\n",
    "    if testing:\n",
    "        student_sets = pd.DataFrame.from_dict(make_student_sets(chattiness = 10, n=2000), orient='index')\n",
    "    else:\n",
    "        pickle_file = f\"{student_sets_file_prefix}.pickle\"\n",
    "        if os.path.isfile(pickle_file) and not overwrite:\n",
    "            with open(pickle_file, 'rb') as f:\n",
    "                student_sets = pickle.load(f)\n",
    "            pp(8, f\"loaded {pickle_file}\")\n",
    "        else:\n",
    "            pp(8, \"generating\")\n",
    "            student_sets = pd.DataFrame.from_dict(make_student_sets(n=2000), orient='index')\n",
    "            with open(pickle_file, 'wb') as f:\n",
    "                pickle.dump(student_sets, f)\n",
    "            pp(8, f\"saved {pickle_file}\")\n",
    "    return student_sets\n",
    "\n",
    "def plot_student_curves(student_sets):\n",
    "    for set_name, meta in student_sets.iterrows():\n",
    "        print(f\"'{set_name}' ({len(meta['sc']['bsp'])} students)\")\n",
    "        plot_student_curve(meta['sc'])\n",
    "\n",
    "student_sets_file_prefix = 'student_sets'\n",
    "student_sets = load_student_sets(student_sets_file_prefix=student_sets_file_prefix, testing=False)\n",
    "plot_student_curves(student_sets)\n",
    "student_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_trial_data(subject_n, attempt_n, trials, groups, sac):\n",
    "    attempt_data = []\n",
    "    participant_data = []\n",
    "    trial_data = []\n",
    "    totals = {}\n",
    "    attempts_per_group = trials*subject_n*attempt_n\n",
    "    print(f\"{attempts_per_group} total attempts per group\")\n",
    "    for trial in range(trials):\n",
    "        pp(7,f\"=======\\ntrial {trial}\")\n",
    "        for group, success_relative_increase in groups.items():\n",
    "            pp(6, f\"group: {group}\")\n",
    "            students = sac[np.random.choice(len(sac), subject_n, replace=True), :attempt_n]\n",
    "            pp(5,students)\n",
    "            result = succeeded(students,success_relative_increase)\n",
    "            pp(6, f\"result: {result}\")\n",
    "            pp(6, f\"{group} success: {result.sum()}/{(result.size)} ({100*result.sum()/(result.size):3.1f}%)\" )\n",
    "            totals[group] = totals.get(group, 0) + result.sum()\n",
    "            rec = {'trial': trial, 'group': group, \"result\": result.sum()}\n",
    "            trial_data.append(rec)\n",
    "            for p in range(subject_n):\n",
    "                participant_results = result[p]\n",
    "                rec[\"p\"] = f\"{group}{p}\"\n",
    "                prec = {**rec, \"result\": participant_results.sum()}\n",
    "                pp(1,prec)\n",
    "                participant_data.append(prec)\n",
    "                for i in range(len(participant_results)):\n",
    "                    irec = {**rec, \"pint\": p, \"i\": i, \"result\": 1 if participant_results[i] else 0}\n",
    "                    pp(1,irec)\n",
    "                    attempt_data.append(irec)\n",
    "\n",
    "    pp(5, f\"totals: {totals}\")\n",
    "    td = pd.DataFrame(trial_data)\n",
    "    partd = pd.DataFrame(participant_data)\n",
    "    ad = pd.DataFrame(attempt_data)\n",
    "    return td, partd, ad, totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trial_plots(td, partd, ad, box=False):\n",
    "    if box:\n",
    "        whisker = 5\n",
    "        ax = sns.boxplot(x=\"group\", y=\"result\", data=td, whis=[whisker, 100-whisker])\n",
    "        title_msg =  \" (Whiskers at {whisker}% and {100-whisker}%)\"\n",
    "    else:\n",
    "        title_msg =  \"\"\n",
    "    #ax = sns.swarmplot(x=\"group\", y=\"result\", data=td)\n",
    "    ax = sns.violinplot(x=\"group\", y=\"result\", data=td)\n",
    "    ax.set_ylabel('Successes (count)')\n",
    "    ax.set_xlabel('Group')\n",
    "    plt.title(f\"Successful attempts in each arm of {ad.trial.max()+1} trials of {int(len(partd)/len(td))} students, each having {int(len(ad)/len(partd))} attempts.{title_msg}\")\n",
    "    plt.show()\n",
    "    pd.crosstab(ad.result, ad.i).plot(kind='bar')\n",
    "    plt.title(\"Success per iteration\")\n",
    "    plt.show()\n",
    "    ad.groupby(['group', 'i']).result.sum().plot(stacked=True,kind='bar')\n",
    "    plt.title(\"Success per iteration\")\n",
    "    plt.show()\n",
    "    \n",
    "def test_trial_generation(sac, groups, subject_n = 5, attempt_n = 5, trials = 1000):\n",
    "    global verbosity\n",
    "    verbosity = 10 if trials < 3 else 6 if trials < 10 else 2  # range of 0-10\n",
    "    print(f\"verbosity: {verbosity}\")\n",
    "    print(f\"{trials} trials sampling {subject_n} for each of {len(groups)} groups out of {sac.shape[0]} students, each having {attempt_n} attempts\")\n",
    "    td, partd, ad, totals = generate_trial_data(subject_n, attempt_n, trials, groups, sac)\n",
    "\n",
    "    def sumarise_trial(totals, attempts_per_group):\n",
    "        results_percents = {}\n",
    "        for group, result in totals.items():\n",
    "            print(group, result)\n",
    "            results_percents[group] = 100*result/attempts_per_group\n",
    "        print(results_percents)\n",
    "    sumarise_trial(totals, attempts_per_group=subject_n*attempt_n*trials)\n",
    "\n",
    "    return td, partd, ad\n",
    "\n",
    "# groups = {\"control\": 0, \"interventionA\":0.1, \"interventionB\":0.2, \"interventionC\":0.6, \"nodif\": 0}\n",
    "#td, partd, ad = test_trial_generation(sac, groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm \n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.formula.api import gee\n",
    "\n",
    "\"\"\"\n",
    "see: https://www.statsmodels.org/dev/_modules/statsmodels/genmod/cov_struct.html#CovStruct \n",
    "\"\"\"\n",
    "def fit_models(ad, trials_to_test, tests):\n",
    "    report_style = 'flat'\n",
    "    outcomes = {}\n",
    "    for trial in trials_to_test:\n",
    "        if not trial % 100:\n",
    "            print(\">\",end='')\n",
    "        pp(5, f\"#### trial: {trial} #####\")\n",
    "        itd = ad.query(f\"trial == {trial}\") # individual trial data\n",
    "        c = itd[['group','result']].groupby(\"group\").sum().reset_index().set_index(\"group\")\n",
    "        res = False # reset to prevent accidental carryover\n",
    "        for model in tests:\n",
    "            pp(5, f\"#### {model}\")\n",
    "            if model == 'ols':\n",
    "                res = ols('result ~ C(group)+i', data=itd).fit()\n",
    "            elif model == 'geeB':\n",
    "                fam = sm.families.Binomial()\n",
    "                ind = sm.cov_struct.Exchangeable()\n",
    "                mod = gee(\"result ~ C(group)+i\", \"p\", itd,\n",
    "                              cov_struct=ind, family=fam)\n",
    "                res = mod.fit()\n",
    "            elif model == 'geeBI':\n",
    "                fam = sm.families.Binomial()\n",
    "                ind = sm.cov_struct.Independence()\n",
    "                mod = gee(\"result ~ C(group)+i\", \"p\", itd,\n",
    "                              cov_struct=ind, family=fam)\n",
    "                res = mod.fit()\n",
    "            elif model == 'geeBIs': # drop the \"i\" variable (which tracks attempt number)\n",
    "                fam = sm.families.Binomial()\n",
    "                ind = sm.cov_struct.Independence()\n",
    "                mod = gee(\"result ~ C(group)\", \"p\", itd,\n",
    "                              cov_struct=ind, family=fam)\n",
    "                res = mod.fit()\n",
    "            elif model == 'gee':\n",
    "                fam = sm.families.Poisson()\n",
    "                ind = sm.cov_struct.Exchangeable()\n",
    "                mod = gee(\"result ~ C(group)+i\", \"p\", itd,\n",
    "                              cov_struct=ind, family=fam)\n",
    "                res = mod.fit()\n",
    "            else:\n",
    "                raise(f\"bad model: {model}\")\n",
    "            pp(3, res.summary())\n",
    "            p=res.pvalues[1]\n",
    "            outcome = 'ns' if p > 0.05 else 'wrong' if c['result'][0] > c['result'][1] else 'sig' if p> 0.01 else 'vsig'\n",
    "            pp(6, f\"******************p = {p:0.6f} -{outcome}\")\n",
    "            if report_style == 'flat':\n",
    "                key = f\"{model}{outcome}\"\n",
    "                if outcomes.get(key, -1) == -1:\n",
    "                    outcomes.update({f\"{model}wrong\":0,f\"{model}ns\":0,f\"{model}sig\":0,f\"{model}vsig\":0,f\"{model}p\":0})\n",
    "                outcomes[key] += 1\n",
    "                outcomes[f\"{model}p\"] += p\n",
    "\n",
    "            else:\n",
    "                outcomes[model] = outcomes.get(model,{'wrong':0,'ns':0,'sig':0,'vsig':0})\n",
    "                outcomes[model][outcome] = 1 + outcomes[model].get(outcome, 0)\n",
    "\n",
    "    return(outcomes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_trials(trial_cache_dir):\n",
    "    pp(10, f'reading {trial_cache_dir}')\n",
    "    ad = pd.read_csv(f\"{trial_cache_dir}/ad.csv.gzip\", compression='gzip')\n",
    "    partd = pd.read_csv(f\"{trial_cache_dir}/partd.csv\")\n",
    "    td = pd.read_csv(f\"{trial_cache_dir}/td.csv\")\n",
    "    return td, partd, ad\n",
    "    pp(10, 'done')\n",
    "\n",
    "def write_trials(td, partd, ad, trial_cache_dir, overwrite=False):\n",
    "    Path(trial_cache_dir).mkdir(parents=True, exist_ok=not overwrite)\n",
    "    pp(10, f'writing {trial_cache_dir}')\n",
    "    ad.to_csv(f\"{trial_cache_dir}/ad.csv.gzip\", compression='gzip')\n",
    "    partd.to_csv(f\"{trial_cache_dir}/partd.csv\")\n",
    "    td.to_csv(f\"{trial_cache_dir}/td.csv\")\n",
    "    pp(10, 'done')\n",
    "\n",
    "def get_trials(student_sets, trialn = 100, subject_n = 200, attempt_n = 20):\n",
    "    trials = {}\n",
    "    for student_set_name, student_meta in student_sets.iterrows():\n",
    "        print(f\"'{student_set_name}' ({len(student_meta['sc']['bsp'])} students)\")\n",
    "        trial_cache_dir = f\"trial_cache/{student_set_name}_{trialn}_{subject_n}_{attempt_n}\"\n",
    "        if os.path.isdir(trial_cache_dir):\n",
    "            td, partd, ad = read_trials(trial_cache_dir)\n",
    "        else:\n",
    "            print(f\"generating fresh trial data\")\n",
    "            print(f\"using '{student_set_name}' ({len(student_meta['sc']['bsp'])} students)\")\n",
    "            groups = {\"control\": 0, \"interventionA\":0.1, \"interventionB\":0.2,\n",
    "                      \"interventionBa\":0.4, \"interventionBb\":0.5,\n",
    "                      \"interventionC\":0.6, \"interventionD\": 0.8, \"nodif\": 0}\n",
    "            td, partd, ad = test_trial_generation(student_meta['sac'], groups, subject_n = subject_n, attempt_n = attempt_n, trials = trialn)\n",
    "            write_trials(td, partd, ad, trial_cache_dir, overwrite=False)\n",
    "        trials[student_set_name] = {\"td\":td,\"partd\":partd,\"ad\":ad}\n",
    "    return trials\n",
    "\n",
    "## add some more arms to the trials and save in new directory\n",
    "\"\"\"\n",
    "if addintervention:\n",
    "    new_trial_cache_dir = f\"{trial_cache_dir}e\"\n",
    "    groups = {\"interventionBa\":0.4, \"interventionBb\":0.5}\n",
    "    pop_type = 'tight'\n",
    "\"\"\"                 \n",
    "def extend_trial(td, partd, ad, groups, new_trial_cache_dir, subject_n = 200, attempt_n = 20):\n",
    "    print(\"generating extra trial data\")\n",
    "    trial_cache_dir = f\"trial_cache_{pop_type}{trialn}\"\n",
    "    tde, partde, ade = test_trial_generation(sac, groups, subject_n = subject_n, attempt_n = attempt_n, trials = trialn)\n",
    "    td = td.append(tde)\n",
    "    ad = ad.append(ade)\n",
    "    partd = partd.append(partd)\n",
    "    write_trials(td, partd, ad, new_trial_cache_dir)\n",
    "\n",
    "\n",
    "#trials = get_trials(student_sets, trialn = 10, subject_n = 10, attempt_n = 5)     \n",
    "trials = get_trials(student_sets, trialn = 100, subject_n = 400, attempt_n = 20)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Summary of trials done on different student populations\")\n",
    "for student_set, trial in trials.items():\n",
    "    ad = trial['ad']\n",
    "    group_totals = ad[['group','result']].groupby('group').agg(['mean', 'sum', 'count'])\n",
    "    print(student_set)\n",
    "    display(group_totals)\n",
    "    trial_plots(trial['td'], trial['partd'], trial['ad'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_sym(student_set, attempt_data, pairs, tests, trials_to_test, spg, aps,\n",
    "    run_key=\"A\",cache_path=\"cache/\"):\n",
    "    print('.', end='')\n",
    "    global verbosity\n",
    "    verbosity = 6 if trials_to_test < 5 else 4\n",
    "    sym_results = []\n",
    "    for comparision, pair in pairs.items():\n",
    "        for students_per_group in spg: #[5, 10]:\n",
    "            for attempts_per_student in aps: #[5,10]:\n",
    "                # attempt to read from a cache file\n",
    "                key = f\"{run_key}.{trials_to_test}{comparision}.{students_per_group}.{attempts_per_student}\"\n",
    "                file = f\"{cache_path}/{student_set}/{key}.json\"\n",
    "                if os.path.isfile(file):\n",
    "                    with open(file) as f:\n",
    "                        rec = json.load(f)\n",
    "                    pp(8, f\"loaded {file}\")\n",
    "                else:\n",
    "                    query = f\"group == {pair} and pint < {students_per_group} and i < {attempts_per_student}\"\n",
    "                    trial_data = attempt_data.query(query)\n",
    "                    pp(10, f\"`{query}` ({len(trial_data)} total attempts)\")\n",
    "                    run_results = fit_models(ad=trial_data, trials_to_test=range(trials_to_test), tests=tests)\n",
    "                    pp(10, f\"run_results: {run_results}\")\n",
    "                    rec = {\"student_set\": student_set,\n",
    "                         \"comparision\":comparision, \n",
    "                         \"students_per_group\": students_per_group, \n",
    "                         \"attempts_per_student\": attempts_per_student,\n",
    "                         \"groupA\": pair[0], \"groupB\": pair[1], \n",
    "                         \"total_attempts\": len(trial_data),\n",
    "                         \"trials\": trials_to_test,\n",
    "                         **run_results,\n",
    "                         'query': query, 'time':time.time()*1000,\n",
    "                         'key': key}\n",
    "                    Path(os.path.dirname(file)).mkdir(parents=True, exist_ok=True) # make the cache dir\n",
    "                    with open(file, 'w') as f:\n",
    "                        pp(8, f\"saving {file}\")\n",
    "                        json.dump(rec, f)\n",
    "                sym_results.append(rec)\n",
    "    return pd.DataFrame(sym_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test(testing = True, phase=0):\n",
    "    pairs = {'none': ['control','nodif'],\n",
    "                 'vsmall': ['control','interventionA'],\n",
    "                 'small': ['control','interventionB'],\n",
    "                 'mod': ['control','interventionBa'],\n",
    "                 'mod1': ['control','interventionBb'],\n",
    "                 'big': ['control', 'interventionC'],\n",
    "                 'huge': ['control', 'interventionD'],\n",
    "                 'upper': [ 'interventionC', 'interventionD']\n",
    "                }\n",
    "    if testing:\n",
    "        students_per_group = [5]\n",
    "        attempts_per_student = [5]\n",
    "        trials_to_test = 3\n",
    "        cache = \"cache_test/\"\n",
    "    else:\n",
    "        students_per_group = [30] if phase == 0 else [30, 75, 100] if phase == 1 else [20, 30, 50, 75, 100, 200, 400]\n",
    "        attempts_per_student = [10] if phase < 2 else [10,20]\n",
    "        trials_to_test = trials['uniform']['ad'].trial.max()+1\n",
    "        cache=\"cache2/\"\n",
    "\n",
    "    print(f\"testing {trials_to_test} trials\")\n",
    "    syms = [] # temporyary value replaced with a dataframe\n",
    "    for student_set, trial in trials.items():\n",
    "        ad = trial['ad']\n",
    "        sym = run_sym(\n",
    "            student_set = student_set,\n",
    "            attempt_data = ad,\n",
    "            pairs = pairs,\n",
    "            run_key=\"d\", tests = ['geeBIs'],\n",
    "            trials_to_test = trials_to_test,\n",
    "            spg = students_per_group,\n",
    "            aps = attempts_per_student,\n",
    "            #run_key=\"c\",   tests = ['geeB','geeBI','geeBIs']\n",
    "            cache_path=cache)\n",
    "        # accumulate all the results into a single df\n",
    "        syms = syms.append(sym) if len(syms) else sym\n",
    "    return syms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "testing = False\n",
    "#test3 = run_test(testing=testing)\n",
    "#test4 = run_test(testing=False)\n",
    "for phase in range(3):\n",
    "    print(f\"phase {phase}+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "    test3 = run_test(testing=testing, phase=phase)\n",
    "    test3.to_csv(f'test10a.{phase}.csv')\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import nan\n",
    "def explain_pairs(pairs, sets):\n",
    "    x = []\n",
    "    for name, pair in pairs.items():\n",
    "        ga = pair[1]\n",
    "        print(ga)\n",
    "        x1 = {\"name\": name, **{set: sets[set].get(ga, nan)-sets[set][pair[0]] for set in sets}}\n",
    "        x.append(x1)\n",
    "    return pd.DataFrame(x)\n",
    "        \n",
    "#sets[set][pair[0]]\n",
    "\n",
    "\n",
    "pairs = {'none': ['control','nodif'],\n",
    "                 'vsmall': ['control','interventionA'],\n",
    "                 'small': ['control','interventionB'],\n",
    "                 'mod': ['control','interventionBa'],\n",
    "                 'mod1': ['control','interventionBb'],\n",
    "                 'big': ['control', 'interventionC'],\n",
    "                 'huge': ['control', 'interventionD'],\n",
    "                 'upper': [ 'interventionC', 'interventionD']\n",
    "                 }\n",
    "sets = {\n",
    "    \"clasic\": {'control': 51.6145, 'interventionA': 55.88775, 'interventionB': 59.653125, \n",
    "     'interventionC': 69.713125, 'interventionD': 73.108, 'nodif': 51.515}, \n",
    "   \"tight\":\n",
    "    {'control': 74.628, 'interventionA': 77.073, 'interventionB': 78.851,\n",
    "     'interventionBa': 82.00075, 'interventionC': 84.128, 'interventionD': 85.87575, 'nodif': 74.71025}\n",
    "}\n",
    "explain_pairs(pairs, sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
